{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('test3').getOrCreate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<pyspark.sql.session.SparkSession at 0x106182a30>",
      "text/html": "\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://daniels-mbp-7.lan:4042\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.3.0</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>test3</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "df = spark.read.csv('pysparkex.csv', header=True, inferSchema=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+------+\n",
      "|  Name| Age|Experience|Salary|\n",
      "+------+----+----------+------+\n",
      "|   Dan|  24|        10| 85000|\n",
      "|Drake |  25|         8| 80000|\n",
      "|  Remy|  33|         4| 65000|\n",
      "|Ashley|  21|         2| 75000|\n",
      "|  Tana|  70|         7| 96000|\n",
      "|Johnny|  19|         5|100000|\n",
      "|Connor|  38|         9| 99000|\n",
      "|Hailey|null|      null|110000|\n",
      "|  null|  22|         6| 50000|\n",
      "|  null|  10|      null|  null|\n",
      "+------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.csv('pysparkex.csv', header=True, inferSchema=True).show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+------+\n",
      "| Age|Experience|Salary|\n",
      "+----+----------+------+\n",
      "|  24|        10| 85000|\n",
      "|  25|         8| 80000|\n",
      "|  33|         4| 65000|\n",
      "|  21|         2| 75000|\n",
      "|  70|         7| 96000|\n",
      "|  19|         5|100000|\n",
      "|  38|         9| 99000|\n",
      "|null|      null|110000|\n",
      "|  22|         6| 50000|\n",
      "|  10|      null|  null|\n",
      "+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#drop the col\n",
    "df.drop('Name').show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+\n",
      "|  Name|Age|Experience|Salary|\n",
      "+------+---+----------+------+\n",
      "|   Dan| 24|        10| 85000|\n",
      "|Drake | 25|         8| 80000|\n",
      "|  Remy| 33|         4| 65000|\n",
      "|Ashley| 21|         2| 75000|\n",
      "|  Tana| 70|         7| 96000|\n",
      "|Johnny| 19|         5|100000|\n",
      "|Connor| 38|         9| 99000|\n",
      "+------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#drop row\n",
    "df.na.drop().show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+\n",
      "|  Name|Age|Experience|Salary|\n",
      "+------+---+----------+------+\n",
      "|   Dan| 24|        10| 85000|\n",
      "|Drake | 25|         8| 80000|\n",
      "|  Remy| 33|         4| 65000|\n",
      "|Ashley| 21|         2| 75000|\n",
      "|  Tana| 70|         7| 96000|\n",
      "|Johnny| 19|         5|100000|\n",
      "|Connor| 38|         9| 99000|\n",
      "+------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#drops all values\n",
    "#how -> any is any null values\n",
    "df.na.drop(how='any').show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+------+\n",
      "|  Name| Age|Experience|Salary|\n",
      "+------+----+----------+------+\n",
      "|   Dan|  24|        10| 85000|\n",
      "|Drake |  25|         8| 80000|\n",
      "|  Remy|  33|         4| 65000|\n",
      "|Ashley|  21|         2| 75000|\n",
      "|  Tana|  70|         7| 96000|\n",
      "|Johnny|  19|         5|100000|\n",
      "|Connor|  38|         9| 99000|\n",
      "|Hailey|null|      null|110000|\n",
      "|  null|  22|         6| 50000|\n",
      "+------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#thresh num at least 2 or more nulls in row\n",
    "df.na.drop(how='any',thresh=2).show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+------+\n",
      "|  Name| Age|Experience|Salary|\n",
      "+------+----+----------+------+\n",
      "|   Dan|  24|        10| 85000|\n",
      "|Drake |  25|         8| 80000|\n",
      "|  Remy|  33|         4| 65000|\n",
      "|Ashley|  21|         2| 75000|\n",
      "|  Tana|  70|         7| 96000|\n",
      "|Johnny|  19|         5|100000|\n",
      "|Connor|  38|         9| 99000|\n",
      "|Hailey|null|      null|110000|\n",
      "|  null|  22|         6| 50000|\n",
      "|  null|  10|      null|  null|\n",
      "+------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+\n",
      "|  Name|Age|Experience|Salary|\n",
      "+------+---+----------+------+\n",
      "|   Dan| 24|        10| 85000|\n",
      "|Drake | 25|         8| 80000|\n",
      "|  Remy| 33|         4| 65000|\n",
      "|Ashley| 21|         2| 75000|\n",
      "|  Tana| 70|         7| 96000|\n",
      "|Johnny| 19|         5|100000|\n",
      "|Connor| 38|         9| 99000|\n",
      "|  null| 22|         6| 50000|\n",
      "+------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#subset\n",
    "df.na.drop(how='any', subset=['Experience']).show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+------+\n",
      "|  Name| Age|Experience|Salary|\n",
      "+------+----+----------+------+\n",
      "|   Dan|  24|        10| 85000|\n",
      "|Drake |  25|         8| 80000|\n",
      "|  Remy|  33|         4| 65000|\n",
      "|Ashley|  21|         2| 75000|\n",
      "|  Tana|  70|         7| 96000|\n",
      "|Johnny|  19|         5|100000|\n",
      "|Connor|  38|         9| 99000|\n",
      "|Hailey|null|      null|110000|\n",
      "|     ?|  22|         6| 50000|\n",
      "|     ?|  10|      null|  null|\n",
      "+------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fill missing values\n",
    "df.na.fill(\"?\").show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols=['Age', 'Experience', 'Salary'],\n",
    "    outputCols=['{}_imputed'.format(c) for c in ['Age', 'Experience', 'Salary']]).setStrategy('mean')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+------+-----------+------------------+--------------+\n",
      "|  Name| Age|Experience|Salary|Age_imputed|Experience_imputed|Salary_imputed|\n",
      "+------+----+----------+------+-----------+------------------+--------------+\n",
      "|   Dan|  24|        10| 85000|         24|                10|         85000|\n",
      "|Drake |  25|         8| 80000|         25|                 8|         80000|\n",
      "|  Remy|  33|         4| 65000|         33|                 4|         65000|\n",
      "|Ashley|  21|         2| 75000|         21|                 2|         75000|\n",
      "|  Tana|  70|         7| 96000|         70|                 7|         96000|\n",
      "|Johnny|  19|         5|100000|         19|                 5|        100000|\n",
      "|Connor|  38|         9| 99000|         38|                 9|         99000|\n",
      "|Hailey|null|      null|110000|         29|                 6|        110000|\n",
      "|  null|  22|         6| 50000|         22|                 6|         50000|\n",
      "|  null|  10|      null|  null|         10|                 6|         84444|\n",
      "+------+----+----------+------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#add imputation cols to df\n",
    "imputer.fit(df).transform(df).show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}